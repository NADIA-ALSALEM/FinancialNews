# -*- coding: utf-8 -*-
"""Financial News Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yXU-lmf0UAeTUXOvo_cBF-aMW9HM0kEY
"""

import pandas as pd

# Load the dataset
news_df = pd.read_csv('news.csv')

# Check basic info and the first few rows
news_df_info = news_df.info()
news_df_head = news_df.head()

news_df_info, news_df_head

# Check for missing values and sentiment distribution
missing_values = news_df.isnull().sum()
sentiment_distribution = news_df['sentiment'].value_counts(normalize=True) * 100

missing_values, sentiment_distribution

# Add a column for news length (number of words)
news_df['news_length'] = news_df['news'].apply(lambda x: len(x.split()))

# Calculate basic statistics for news length
length_stats = news_df['news_length'].describe()

# Plot sentiment-based news length distribution
length_by_sentiment = news_df.groupby('sentiment')['news_length'].describe()

length_stats, length_by_sentiment

from collections import Counter
from wordcloud import STOPWORDS
import re

# Define stop words and regex pattern to clean text
stop_words = set(STOPWORDS)
pattern = r'\b\w{1,2}\b|\d+'  # Remove short words (1-2 chars) and numbers

# Function to get most common words
def get_top_words(texts, n=20):
    words = ' '.join(texts).lower()
    words = re.sub(pattern, '', words)
    words = [word for word in words.split() if word not in stop_words]
    return Counter(words).most_common(n)

# Get top words for positive and negative news
positive_words = get_top_words(news_df[news_df['sentiment'] == 'POSITIVE']['news'])
negative_words = get_top_words(news_df[news_df['sentiment'] == 'NEGATIVE']['news'])

positive_words, negative_words

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# positive word cloud
positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(positive_words))

plt.figure(figsize=(10, 5))
plt.imshow(positive_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('positive word cloud')
plt.show()

# negarive word cloud
negative_wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(negative_words))

plt.figure(figsize=(10, 5))
plt.imshow(negative_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('negative word cloud')
plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(news_df['news'], news_df['sentiment'], test_size=0.2, random_state=42)

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

# Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
y_pred = model.predict(X_test_tfidf)

accuracy = accuracy_score(y_test, y_pred)
print(f"accuracy: {accuracy:.2f}")

print("classification report:")
print(classification_report(y_test, y_pred))

print("confusion matrix:")
print(confusion_matrix(y_test, y_pred))

import joblib

# save model
joblib.dump(model, 'logistic_regression_model.pkl')
joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')

import joblib

loaded_model = joblib.load('logistic_regression_model.pkl')
loaded_tfidf = joblib.load('tfidf_vectorizer.pkl')

new_text = ["It was a long antipodean night. While thereÃ¢â‚¬â„¢s no telling whatÃ¢â‚¬â„¢s a reflection of national taste and whatÃ¢â‚¬â„¢s the result of booking expediency, each of the concerts from Australia, Japan and China certainly had its own character."]

new_text_tfidf = loaded_tfidf.transform(new_text)

prediction = loaded_model.predict(new_text_tfidf)
print(prediction)

!pip install fastapi uvicorn

Commented out IPython magic to ensure Python compatibility.
%%writefile app.py
from fastapi import FastAPI
import joblib

# Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ FastAPI
app = FastAPI()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…ØªØ¬Ù‡Ø§Øª
model = joblib.load('logistic_regression_model.pkl')
tfidf = joblib.load('tfidf_vectorizer.pkl')

# ØªØ¹Ø±ÙŠÙ Ù…Ø³Ø§Ø± API
@app.post("/predict")
def predict(text: str):
    text_tfidf = tfidf.transform([text])
    prediction = model.predict(text_tfidf)
    return {"prediction": prediction[0]}



pip install streamlit

import streamlit as st
import joblib

# load the model and vectorizer
model = joblib.load('logistic_regression_model.pkl')
tfidf = joblib.load('tfidf_vectorizer.pkl')

st.title('Financial News Classification')

# ÙˆØ§Ø¬Ù‡Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ
user_input = st.text_area("Input the Financial News here: ")

# Ø²Ø± Ù„Ù„ØªÙ†Ø¨Ø¤
if st.button('Classify the News'):
    if user_input:

        text_tfidf = tfidf.transform([user_input])

        prediction = model.predict(text_tfidf)

        if prediction[0] == 'POSITIVE':
            st.success('Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠ! ğŸ“ˆ')
        else:
            st.error('Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ø³Ù„Ø¨ÙŠ! ğŸ“‰')
    else:
        st.warning('ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ø§Ù„Ø®Ø¨Ø± Ø£ÙˆÙ„Ø§Ù‹.')
