# -*- coding: utf-8 -*-
"""Financial News Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yXU-lmf0UAeTUXOvo_cBF-aMW9HM0kEY
"""

import pandas as pd

# Load the dataset
news_df = pd.read_csv('news.csv')

# Check basic info and the first few rows
news_df_info = news_df.info()
news_df_head = news_df.head()

news_df_info, news_df_head

# Check for missing values and sentiment distribution
missing_values = news_df.isnull().sum()
sentiment_distribution = news_df['sentiment'].value_counts(normalize=True) * 100

missing_values, sentiment_distribution

# Add a column for news length (number of words)
news_df['news_length'] = news_df['news'].apply(lambda x: len(x.split()))

# Calculate basic statistics for news length
length_stats = news_df['news_length'].describe()

# Plot sentiment-based news length distribution
length_by_sentiment = news_df.groupby('sentiment')['news_length'].describe()

length_stats, length_by_sentiment

from collections import Counter
from wordcloud import STOPWORDS
import re

# Define stop words and regex pattern to clean text
stop_words = set(STOPWORDS)
pattern = r'\b\w{1,2}\b|\d+'  # Remove short words (1-2 chars) and numbers

# Function to get most common words
def get_top_words(texts, n=20):
    words = ' '.join(texts).lower()
    words = re.sub(pattern, '', words)
    words = [word for word in words.split() if word not in stop_words]
    return Counter(words).most_common(n)

# Get top words for positive and negative news
positive_words = get_top_words(news_df[news_df['sentiment'] == 'POSITIVE']['news'])
negative_words = get_top_words(news_df[news_df['sentiment'] == 'NEGATIVE']['news'])

positive_words, negative_words

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# positive word cloud
positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(positive_words))

plt.figure(figsize=(10, 5))
plt.imshow(positive_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('positive word cloud')
plt.show()

# negarive word cloud
negative_wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(negative_words))

plt.figure(figsize=(10, 5))
plt.imshow(negative_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('negative word cloud')
plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(news_df['news'], news_df['sentiment'], test_size=0.2, random_state=42)

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# تدريب النموذج
model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

# التنبؤ على بيانات الاختبار
y_pred = model.predict(X_test_tfidf)

accuracy = accuracy_score(y_test, y_pred)
print(f"accuracy: {accuracy:.2f}")

print("classification report:")
print(classification_report(y_test, y_pred))

print("confusion matrix:")
print(confusion_matrix(y_test, y_pred))

import joblib

# save model
joblib.dump(model, 'logistic_regression_model.pkl')
joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')

import joblib

loaded_model = joblib.load('logistic_regression_model.pkl')
loaded_tfidf = joblib.load('tfidf_vectorizer.pkl')

new_text = ["It was a long antipodean night. While thereâ€™s no telling whatâ€™s a reflection of national taste and whatâ€™s the result of booking expediency, each of the concerts from Australia, Japan and China certainly had its own character."]

new_text_tfidf = loaded_tfidf.transform(new_text)

prediction = loaded_model.predict(new_text_tfidf)
print(prediction)

!pip install fastapi uvicorn

Commented out IPython magic to ensure Python compatibility.
%%writefile app.py
from fastapi import FastAPI
import joblib

# إنشاء تطبيق FastAPI
app = FastAPI()

# تحميل النموذج والمتجهات
model = joblib.load('logistic_regression_model.pkl')
tfidf = joblib.load('tfidf_vectorizer.pkl')

# تعريف مسار API
@app.post("/predict")
def predict(text: str):
    text_tfidf = tfidf.transform([text])
    prediction = model.predict(text_tfidf)
    return {"prediction": prediction[0]}



pip install streamlit

import streamlit as st
import joblib

# load the model and vectorizer
model = joblib.load('logistic_regression_model.pkl')
tfidf = joblib.load('tfidf_vectorizer.pkl')

st.title('Financial News Classification')

# واجهة إدخال النص
user_input = st.text_area("Input the Financial News here: ")

# زر للتنبؤ
if st.button('Classify the News'):
    if user_input:

        text_tfidf = tfidf.transform([user_input])

        prediction = model.predict(text_tfidf)

        if prediction[0] == 'POSITIVE':
            st.success('هذا الخبر إيجابي! 📈')
        else:
            st.error('هذا الخبر سلبي! 📉')
    else:
        st.warning('يرجى إدخال نص الخبر أولاً.')
